############################
# Setting for MLRun/Iguazio
############################

# Url to the MLRun API:
#   for Iguazio e.g. https://mlrun-api.default-tenant.app.iguazio-nonprod
#   for Docker Desktop e.g. http://localhost:8080
# Note: Mandatory, MLRun use http not https protocol
MLRUN_DBPATH = http://localhost:8080

# User name to the Iguazio/V3IO login e.g. jist
# Note: Empty for pure MLRun without Iguazio
#V3IO_USERNAME =

# Access key to the Iguazio/V3IO in GUID format e.g. 670068ad-abe0-530f-beb1-c78996d99818
# Note: Empty for pure MLRun without Iguazio
#V3IO_ACCESS_KEY =

# Url to the Iguazio/V3IO e.g. https://webapi.default-tenant.app.iguazio-nonprod
# Note: Empty for pure MLRun without Iguazio
#V3IO_API =

####################
# Setting for QGate
####################
# Anonym mode
#   'On'  - Host value has 'Anonym/192.168.0.1' and Datetime has format '%Y-%m-%d xxxxxxxxxxxx' in output
#   'Off' - Default value, the Host and Datatime contain relevant values
QGATE_ANONYM_MODE = On

# Path to the QGate model definition (the path can be relative or full) e.g. ../qgate-model
QGATE_DEFINITION = ../qgate-model

# Name of data set for testing e.g. "01-size-100", "02-size-1K", etc.
QGATE_DATASET = 01-size-100

# List of projects for testing e.g. agate-1, agate-2, etc.
# Default is empty list (all projects will be tested)
#agate-redis-csv
#agate-redis-parquet
#agate-mysql-csv
#agate-mysql-parquet
#agate-postgres-csv
#agate-postgres-parquet
#agate-kafka
#QGATE_FILTER_PROJECTS = agate-redis-parquet
#QGATE_FILTER_PROJECTS = agate-parquet
#QGATE_FILTER_PROJECTS = agate-redis-csv,agate-redis-parquet,agate-mysql-csv,agate-mysql-parquet,agate-kafka
QGATE_FILTER_PROJECTS = agate-redis-csv

# List of test scenarios for testing e.g. TS201, etc. (it is important to keep TS dependencies).
# Default is empty list (all test scenarios will be tested)
QGATE_FILTER_SCENARIOS = TS101, TS102, TS201, TS601

# Path to the output directory (as off-line storage, valid for target 'parquet' and 'csv')
# sample value e.g. ./output
QGATE_OUTPUT = ./output

# Experiment with s3 and objectstorage
#   data store pattern: ds://<data store>/path/to/file
QGATE_OUTPUT_EXP = ./output, ds://az-blob/jistcontainer01/test/

# Secrets setting for S3, details:
#   Documentation: https://docs.mlrun.org/en/latest/store/datastore.html#s3-data-store-profile
#   Parameters: name, endpoint_url, profile_name,
#   Secret file: access_key_id, secret_key
#QGATE_SECRET_S3 = aws-s3, ./secrets/aws_connection.env

# Secrets setting for ObjectStorage, details
#   Documentation: https://docs.mlrun.org/en/latest/store/datastore.html#azure-data-store-profile
#   Parameters: name, env file
#   Secret file: connection_string
#QGATE_SECRET_AZ = az-blob, ./secrets/az_connection.env

# Global definition for data store with this structure
#   name, type, env file (with secrets for connection)
QGATE_DATA_STORE = az-blob, AzureBlobStorage, ./secrets/az_connection.env

# Relation to Redis (as on-line storage, valid for target 'redis')
# sample value e.g. redis://localhost:6379
QGATE_REDIS = redis://localhost:6379

# Relation to MySQL (as on-line/off-line storage, valid for target 'mysql')
# sample value e.g. mysql+pymysql://testuser:testpwd@localhost:3306/test
QGATE_MYSQL = mysql+pymysql://testuser:testpwd@localhost:3306/test

# Relation to Postgres (as on-line/off-line storage, valid for target 'postgres')
# sample value e.g. postgresql+psycopg2://testuser:testpwd@localhost:5432/test
QGATE_POSTGRES = postgresql+psycopg2://testuser:testpwd@localhost:5432/test

# Relation to Kafka (as on-line source, valid for source 'kafka')
#   format <url>, <topic name>, e.g. localhost:9092, testtopic
QGATE_KAFKA = localhost:9092, testtopic